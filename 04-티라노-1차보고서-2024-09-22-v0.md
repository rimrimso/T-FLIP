<!-- Template for PROJECT REPORT of CapstoneDesign 2024-2H, initially written by khyoo -->
<!-- 본 파일은 2024년도 컴공 졸업프로젝트의 <1차보고서> 작성을 위한 기본 양식입니다. -->
<!-- 아래에 "*"..."*" 표시는 italic체로 출력하기 위해서 사용한 것입니다. -->
<!-- "내용"에 해당하는 부분을 지우고, 여러분 과제의 내용을 작성해 주세요. -->

# Team-Info
| (1) 과제명 | *Lightweighting CLIP for Face Anti-Spoofing via Knowledge Distillation*
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | *04-티라노* |
| (3) 팀원 역할 분담 |  박지원(2076169) : 리더, *AI 모델 개발*   <br> 류이정(2176129) : 팀원, *AI 모델 개발*   <br> 소예림(2071028) : 팀원, *AI 모델 개발*  |
| (4) 팀 지도교수 | 심재형 교수님 |
| (5) 팀 멘토 | 최종원 / 조교수 / 중앙대학교 첨단영상대학원 영상학과 |
| (6) 과제 분류 | 연구 과제 |
| (7) 과제 키워드(keywords) | CLIP, Face Anti Spoofing(FAS), 경량화, knowledge distillation |
| (8) 과제 내용 요약 | FLIP(Face Anti-Spoofing with Language-Image Pretraining)은 멀티모달 모델인 CLIP(Contrastive Language-Image Pretraining)을 Face Anti-Spoofing(FAS) 태스크에 최적화한 모델이다. FLIP은 위조 얼굴을 탐지하는 FAS 태스크에서 다른 모델들에 비해 우수한 성능을 보여준다. 그러나 거대한 모델 구조로 인해 추론에 많은 비용이 발생하며, 엣지 디바이스에 탑재하는 데에 어려움이 있다. 이에 따라, Knowledge Distillation(지식 증류) 방법을 사용하여 FLIP의 우수한 성능을 유지하면서도 더 빠르게 추론할 수 있는 경량화 모델을 개발하고자 한다. |
|:---  |---  |

<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 | 현대 사회에서는 휴대폰 잠금 해제부터 공항 탑승 게이트까지 Face Anti-Spoofing(FAS) 기술이 우리 생활에 밀접하게 사용되고 있습니다. FAS는 보안과 직결되는 기술이지만 더불어 매우 흔하고, 빈번하게 사용되는 기술이기 때문에 높은 성능 뿐 만 아니라 빠른 추론 속도의 필요성 또한 절감했습니다. 어디서든 보안이 필요한 곳이라면 컴퓨팅 능력과 자원이 한정된 디바이스에도 좋은 성능을 보일 수 있어야 합니다. <br><br> 현재 연구에 사용되는 FLIP(Face Anti-Spoofing with Language-Image Pretraining) 모델은 CLIP(Contrastive Language-Image Pretraining) 기반의 멀티모달 모델로서, 이미지와 텍스트 간의 관계를 이해하는 데에 효과적이고 위조 얼굴 탐지(FAS) 태스크에서 뛰어난 성능을 보여줍니다. 그러나 169,568,513개의 파라미터를 가지고 있는 매우 크고 복잡한 모델 구조로 인해 추론 속도가 느리며 또 많은 비용이 발생합니다. 이러한 이유로 FLIP 모델은 실시간 처리가 중요한 엣지 디바이스에 적합하지 않으며, 모바일 기기나 저사양 디바이스에서의 활용이 어렵습니다. <br><br> 따라서 Target Customer는 엣지 컴퓨팅 환경에서 보안이 중요한 애플리케이션을 사용하는 기업 및 개발자들입니다. 이러한 고객들이 직면한 문제점은 다음과 같습니다:<br><br>- **엣지 디바이스 성능 제한**: 위조 얼굴 탐지와 같은 고성능 태스크는 엣지 디바이스에서 수행하기에 자원과 처리 속도 측면에서 많은 제약을 받습니다.<br> - **실시간 위조 탐지 필요성**: 보안성 향상을 위해 위조 얼굴을 실시간으로 탐지하는 기능이 필수적이지만, FLIP 모델의 큰 구조로 인해 처리 속도가 느려 실시간 추론에 적합하지 않습니다.<br> - **추론 비용 문제**: 큰 모델을 클라우드 기반으로 운영할 경우 비용이 많이 들고, 이를 엣지 디바이스에서 수행할 수 있는 경량화된 대안이 필요합니다.|
| (2) 기존연구와의 비교 | 본 과제는 FLIP 모델을 기반으로 FAS 작업에서의 성능과 효율성을 모두 향상시키는 것을 목표로 한다. FLIP을 경량화 하고자 하는 본 과제를 기존 연구들과 비교하여 FAS 과제에서 해당 FLIP 모델을 선택한 이유와, 이 모델을 경량화함으로써 갖는 장점을 설명해보고자 한다. <br><br> 1) 비전 트랜스포머(ViT) 모델을 사용한 FAS 연구[1][2] : <br> 최근 ViT 모델은 이미지 패치 간의 장거리 의존성을 포착하는 능력 덕분에 FAS 작업에 효과적인 것으로 나타났다. 그러나 해당 연구에는 두 가지 한계점이 있다. 첫째, 이미지 데이터만을 사용하여 학습하기 때문에 제한된 학습 데이터를 사용할 때 일반화 능력을 제한한다. 둘째, 사전 학습된 가중치를 미세 조정하기 위해 추가적인 네트워크 수정이나 도메인 레이블과 같은 추가 정보 구성 작업을 필요로 한다. 반면, Tyrano-FLIP에서 선택한 FLIP 모델은 이미지와 텍스트를 결합한 멀티모달 모델 사전학습 가중치로 ViT를 초기화하는 과정을 거쳐 더욱 향상된 FAS 성능을 보여준다. 또한, 이미지 표현을 클래스를 설명하는 텍스트 집합과 정렬하기 때문에, 데이터가 적은 상황에서도 FAS의 일반화 성능이 향상된다. <br><br> 2) CLIP(Contrastive Language-Image Pretraining) Knowledge distillation 연구[3][4][5] : <br> 국내외에서는 이미지와 텍스트를 동시에 이해하는 멀티모달 인공지능 모델의 개발이 활발히 진행되고 있다. FLIP 모델은 멀티모달 모델인 CLIP을 FAS 태스크에 최적화시킨 모델로서 CLIP의 아키텍쳐에 그 기반을 두고 있다. CLIP 모델을 경량화하고자 했던 이전 연구를 살펴보면, Tiny-CLIP, CLIP-KD, RKD 등의 연구는 CLIP과 유사한 성능을 유지하면서 파라미터 수를 효과적으로 감소시켜 다양한 knowledge distillation 기법의 효용성을 입증했다. 그러나 CLIP은 FAS 작업에 최적화된 모델이 아닐 뿐 더러, CLIP과 유사한 구조를 가진 FLIP에 대해서는 아직 경량화 시도가 진행된 바가 없다. 따라서 본 프로젝트에서는 FAS 과제에 최적화된 모델의 경량화를 해내고자 FLIP에 knowledge distillation을 적용하였다. <br><br> 위와 같은 이유로 본 연구는 기존에 시도되지 않았던 FLIP 모델을 knowledge distillation으로 경량화하는 독창적인 시도를 통해 Tyrano-FLIP이 비교적 우수한 FAS 성능과 빠른 추론 속도를 가질 것이라 예상하며, 나아가 실제 환경에서 FAS 태스크의 적용 가능성을 높일 것이라 기대한다. <br><br> 출처 : <br>  [1]  Anjith George and Se ́bastien Marcel. On the effectiveness of vision transformers for zero-shot face anti-spoofing. In 2021 IEEE International Joint Conference on Biometrics (IJCB), pages 1–8. IEEE, 2021. <br> [2] Hsin-PingHuang,DeqingSun,YaojieLiu,Wen-ShengChu, Taihong Xiao, Jinwei Yuan, Hartwig Adam, and Ming- Hsuan Yang. Adaptive transformers for robust few-shot cross-domain face anti-spoofing. In Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XIII, pages 37–54. Springer, 2022. <br> [3] Wu, Kan, et al. "Tinyclip: Clip distillation via affinity mimicking and weight inheritance." Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023. <br> [4] Yang, Chuanguang, et al. "CLIP-KD: An Empirical Study of Distilling CLIP Models." arXiv preprint arXiv:2307.12732, 2023. <br> [5] Park, Wonpyo, et al. "Relational knowledge distillation." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.|
| (3) 제안 내용 | (다른 모델의 light weighting 연구는 있지만, 성능이 가장 좋은 FLIP 모델에 대해서 경량화 한 연구 배경은 아무것도 없음을 강조 (FLIP 파라미터 수, 추론 속도 등 언급하면 좋을 듯) <br>본 연구 프로젝트에서는 FAS의 추론속도를 향상시키기 위해서 knowledge distillation(KD) 기술을 도입하여 FLIP 모델을 경량화 하고자 한다. KD란, 큰 네트워크의 지식을 작은 네트워크로 전달하여 작은 네트워크가 큰 네트워크의 성능을 모방하도록 하는 기술이다. <br>(KD 중에서도 FLIP에 적합하도록 logit 위주보다 관계 및 어텐션 맵 위주의 distillation을 도입해본 걸 언급해도될듯)|
| (4) 기대효과 및 의의 |본 연구의 목표는 FAS 기술을 사용하고자 하는 모든 기술 및 기업을 목표 사용자로 하여, FLIP (Face Anti-Spoofing with Language-Image Pretraining) 모델의 추론 속도를 향상시켜 보다 효율적이고 실용적인 사용 환경을 조성하는 것이다. 구체적으로는 다음과 같은 목표를 설정하였다:<br><br> 1. FLIP 모델의 추론 속도를 기존보다 최소 2배 이상 향상시키는 것을 목표로 한다. 이를 통해 모델의 사용성을 향상시키고, 실제 환경에서의 빠른 응답이 가능하도록 한다.<br> 2. 작은 모델에게도 FLIP과 유사한 성능을 제공하여 모델의 크기를 줄이고 자원을 효율적으로 활용할 수 있도록 한다. 이를 통해 모바일 및 임베디드 시스템에서도 FLIP 기술을 적용할 수 있는 환경을 조성한다.<br> 3. 추론 속도의 향상이 모델의 정확도에 부정적인 영향을 미치지 않도록 한다. 즉, 속도와 정확도 간의 균형을 유지하여 실제 사용 시에도 뛰어난 성능을 제공한다.<br> 4. FLIP 모델의 개선을 통해 기업들은 보다 빠르고 정확한 FAS 인공지능 서비스를 제공할 수 있게 되어 산업 혁신과 경쟁력 강화에 기여할 것으로 기대된다.<br><br> 위 목표를 달성함으로써, FAS 태스크의 보안성을 높여 기술 사용자들의 불안함을 해소하고, FLIP 기반의 다중 모달 인공지능 모델을 보다 효율적으로 개발하고 실제 응용 환경에서의 적용 가능성을 높이고자 한다.|
| (5) 주요 기능 리스트 | 1. FD(Feature Distillation): <br> knowledge distillation 방법 중 교사 모델(teacher model)에서 추출한 피처(feature)를 학생 모델(student model)로 증류하는 방법입니다. 교사 모델은 학습 과정에서 여러 단계의 중간 피처를 생성하는데, 이 피처들은 입력 데이터의 특정 속성을 표현하는 중요한 정보입니다. FD의 핵심은 교사 모델의 여러 레이어에서 추출된 피처맵을 학생 모델로 전이시켜, 교사 모델이 학습한 중요한 정보(피처)를 학생 모델이 학습하도록 돕는 것입니다. 이는 단순히 출력 logits를 맞추는 방식보다 더 세밀하게 정보를 전달하는 방법으로, 학생 모델이 더 효율적으로 학습할 수 있게 합니다. <br><br> 2. RKD(Relational Knowledge Distillation): <br> Relational Knowledge Distillation(RKD)은 데이터 간의 관계성(relations)을 기반으로 지식을 증류하는 방법입니다. 일반적인 피처 증류는 교사 모델과 학생 모델 간의 개별 데이터에 대한 매핑에 초점을 맞추는 반면, RKD는 여러 데이터 간의 상호작용이나 관계성을 학습하고 그 관계성을 학생 모델로 전이시키는 것을 목표로 합니다. 이 방법론은 교사 모델이 학습한 데이터 간의 관계성(데이터 포인트 간의 거리, 상대적 위치, 유사성)을 학생 모델이 학습함으로써, 데이터 간의 구조적 정보를 효과적으로 전달합니다. 특히 거리(distances)와 각도(angles)를 사용하여 데이터 간의 상대적 관계를 학습합니다. 이를 통해 학생 모델이 데이터의 구조적 특성을 보존할 수 있도록 유도합니다. <br><br> AFD(Attention-based Feature Distillation(AFD): <br> AFD는 **Attention 메커니즘**을 활용한 지식 증류 방법으로, Show, Attend and Distill 논문에서 제안된 방식입니다. 이 방식에서는 교사 모델이 데이터에 대해 주목하는 부분(Attention)을 학생 모델에 전이하여, 학생 모델이 중요한 피처에 집중할 수 있도록 학습을 진행합니다. Attention 메커니즘은 신경망 모델이 입력 데이터의 특정 부분에 대해 더 많은 가중치를 부여하는 기법으로, 특히 비전 및 NLP 태스크에서 중요한 정보를 선택적으로 학습하는 데 유용합니다. AFD는 이 Attention 메커니즘을 활용하여, 교사 모델의 Attention 지도(attention map)를 학생 모델에 전이시키는 방식을 제안합니다. 이는 교사 모델이 데이터의 어떤 부분에 집중하는지에 대한 정보를 학생 모델에 전달하여, 학생 모델이 중요한 피처를 놓치지 않고 학습할 수 있도록 합니다.|

<br>
 
# Project-Design
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | *프로젝트를 완성하기 위해 필요한 요구사항을 설명하기에 가장 적합한 방법을 선택하여 기술* <br> 예) <br> - 기능별 상세 요구사항(또는 유스케이스) <br> - 설계 모델(클래스 다이어그램, 클래스 및 모듈 명세서) <br> - UI 분석/설계 모델 <br> - E-R 다이어그램/DB 설계 모델(테이블 구조) |
| (2) 전체 시스템 구성 | *프로젝트를 위하여, SW 전체 시스템의 구조를 보인다. (가능하다면, 사용자도 포함) <br> 주요 SW 모듈을 보이고, 각각의 역할을 기술한다. <br>만약, 오픈소스 혹은 외부 모듈을 사용한다면 이또한 기술한다.* |
| (3) 진척도 및 검증내역 | *스타트 단계에서 검증한 내용에 대하여 간략히 기술하고, <br>그로쓰 단계의 전체 일정에 비추어, 진척도(%) 및 근거 내용을 기술한다.* |
| (4) 기타 | *기타 사항을 기술* |

<br>
