<!-- Template for PROJECT REPORT of CapstoneDesign 2024-2H, initially written by khyoo -->
<!-- 본 파일은 2024년도 컴공 졸업프로젝트의 <1차보고서> 작성을 위한 기본 양식입니다. -->
<!-- 아래에 "*"..."*" 표시는 italic체로 출력하기 위해서 사용한 것입니다. -->
<!-- "내용"에 해당하는 부분을 지우고, 여러분 과제의 내용을 작성해 주세요. -->

# Team-Info
| (1) 과제명 | *Lightweighting CLIP for Face Anti-Spoofing via Knowledge Distillation*
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | *04-티라노* |
| (3) 팀원 역할 분담 |  박지원(2076169) : 리더, *AI 모델 개발*   <br> 류이정(2176129) : 팀원, *AI 모델 개발*   <br> 소예림(2071028) : 팀원, *AI 모델 개발*  |
| (4) 팀 지도교수 | 심재형 교수님 |
| (5) 팀 멘토 | 최종원 / 조교수 / 중앙대학교 첨단영상대학원 영상학과 |
| (6) 과제 분류 | 연구 과제 |
| (7) 과제 키워드(keywords) | CLIP, Face Anti Spoofing(FAS), 경량화, knowledge distillation |
| (8) 과제 내용 요약 | FLIP(Face Anti-Spoofing with Language-Image Pretraining)은 멀티모달 모델인 CLIP(Contrastive Language-Image Pretraining)을 Face Anti-Spoofing(FAS) 태스크에 최적화한 모델이다. FLIP은 위조 얼굴을 탐지하는 FAS 태스크에서 다른 모델들에 비해 우수한 성능을 보여준다. 그러나 거대한 모델 구조로 인해 추론에 많은 비용이 발생하며, 엣지 디바이스에 탑재하는 데에 어려움이 있다. 이에 따라, Knowledge Distillation(지식 증류) 방법을 사용하여 FLIP의 우수한 성능을 유지하면서도 더 빠르게 추론할 수 있는 경량화 모델을 개발하고자 한다. |
|:---  |---  |

<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 | 현대 사회에서는 휴대폰 잠금 해제부터 공항 탑승 게이트까지 Face Anti-Spoofing(FAS) 기술이 우리 생활에 밀접하게 사용되고 있습니다. FAS는 보안과 직결되는 기술이지만 더불어 매우 흔하고, 빈번하게 사용되는 기술이기 때문에 높은 성능 뿐 만 아니라 빠른 추론 속도의 필요성 또한 절감했습니다. 어디서든 보안이 필요한 곳이라면 컴퓨팅 능력과 자원이 한정된 디바이스에도 좋은 성능을 보일 수 있어야 합니다. <br> 현재 연구에 사용되는 FLIP(Face Anti-Spoofing with Language-Image Pretraining) 모델은 CLIP(Contrastive Language-Image Pretraining) 기반의 멀티모달 모델로서, 이미지와 텍스트 간의 관계를 이해하는 데에 효과적이고 위조 얼굴 탐지(FAS) 태스크에서 뛰어난 성능을 보여줍니다. 그러나 169,568,513개의 파라미터를 가지고 있는 매우 크고 복잡한 모델 구조로 인해 추론 속도가 느리며 또 많은 비용이 발생합니다. 이러한 이유로 FLIP 모델은 실시간 처리가 중요한 엣지 디바이스에 적합하지 않으며, 모바일 기기나 저사양 디바이스에서의 활용이 어렵습니다. <br> 따라서 Target Customer는 엣지 컴퓨팅 환경에서 보안이 중요한 애플리케이션을 사용하는 기업 및 개발자들입니다. 이러한 고객들이 직면한 문제점은 다음과 같습니다:<br><br>- **엣지 디바이스 성능 제한**: 위조 얼굴 탐지와 같은 고성능 태스크는 엣지 디바이스에서 수행하기에 자원과 처리 속도 측면에서 많은 제약을 받습니다.<br> - **실시간 위조 탐지 필요성**: 보안성 향상을 위해 위조 얼굴을 실시간으로 탐지하는 기능이 필수적이지만, FLIP 모델의 큰 구조로 인해 처리 속도가 느려 실시간 추론에 적합하지 않습니다.<br> - **추론 비용 문제**: 큰 모델을 클라우드 기반으로 운영할 경우 비용이 많이 들고, 이를 엣지 디바이스에서 수행할 수 있는 경량화된 대안이 필요합니다.|
| (2) 기존연구와의 비교 | 본 과제는 FLIP 모델을 기반으로 Face Anti-Spoofing(FAS) 작업에서의 성능과 효율성을 모두 향상시키는 것을 목표로 합니다. 이 과제의 해결을 위해 **Knowledge Distillation(지식 증류)** 기법을 적용하며 기존 연구들을 분석 및 연구하여 본 과제에 적용합니다.<br><br>[기존 연구 분석]<br>1. **CLIP-KD(An Empirical Study of CLIP Model Distillation)**<br>CLIP-KD는 CLIP 모델의 대규모 파라미터를 줄이면서도 성능 손실을 최소화하기 위한 지식 증류 연구입니다. 이 연구는 특히 이미지와 텍스트 간의 관계를 유지하면서, 더 작은 모델이 동일한 멀티모달 특성을 학습할 수 있도록 돕습니다.  CLIP-KD는 CLIP 모델이 지닌 강력한 **멀티모달 학습 능력**을 유지하면서도, 추론 속도를 크게 개선할 수 있는 가능성을 보여줍니다. 학습 시 **텍스트와 이미지 간의 관계성**을 고려함으로써, 멀티모달 태스크에서도 성능을 보존할 수 있습니다.<br> 2. **Relational Knowledge Distillation** <br> 이 연구는 단순히 피처나 로지츠를 증류하는 것에 그치지 않고, **데이터 간의 관계성**을 기반으로 한 지식 증류 방법을 제안합니다. 이는 학생 모델이 데이터의 상호작용이나 유사성을 더 잘 학습하도록 돕는 방식을 도입하였습니다. 데이터 간의 상관관계를 학습하는 방식은 더 풍부한 정보 전이를 가능하게 하며, 학생 모델이 더 높은 일반화 성능을 얻을 수 있도록 합니다. 이러한 방식은 비전 태스크에서 특히 효과적으로, 이미지 간의 유사성 및 관계성을 잘 포착합니다. <br> 3. **Show, Attend and Distill: Knowledge Distillation via Attention-based Feature Matching** <br> 이 연구는 Attention 메커니즘을 통해 지식을 증류하는 방법을 제안합니다. 교사 모델의 Attention 지도를 학생 모델로 전이하여, 중요한 피처에 집중하도록 하는 방식입니다. **Attention 기반의 피처 매칭**은 중요한 정보 손실을 최소화하며, 지식 증류 과정에서 성능을 더 잘 유지할 수 있는 방법입니다. 특히 비전 태스크에서 시각적 중요성을 학습하는 데 강점을 가지고 있어, FAS 작업에도 유용할 수 있습니다. <br><br> [본 과제의 차별성] <br> 위 기존 연구들은 FLIP과 같이 위조 탐지에 직접 적용되는 **Face Anti-Spoofing(FAS)에 특화**된 모델이 아니거나, 멀티모달 모델이 아닌 일반적인 비전 모델을 다루고 있습니다. 본 과제는 위에서 설명한 여러 지식 증류 기법의 장점들을 조합하여 FAS 태스크에 맞게 통합하고 최적화하는 것을 목표로 합니다.|
| (3) 제안 내용 | (다른 모델의 light weighting 연구는 있지만, 성능이 가장 좋은 FLIP 모델에 대해서 경량화 한 연구 배경은 아무것도 없음을 강조 (FLIP 파라미터 수, 추론 속도 등 언급하면 좋을 듯) <br>본 연구 프로젝트에서는 FAS의 추론속도를 향상시키기 위해서 knowledge distillation(KD) 기술을 도입하여 FLIP 모델을 경량화 하고자 한다. KD란, 큰 네트워크의 지식을 작은 네트워크로 전달하여 작은 네트워크가 큰 네트워크의 성능을 모방하도록 하는 기술이다. <br>(KD 중에서도 FLIP에 적합하도록 logit 위주보다 관계 및 어텐션 맵 위주의 distillation을 도입해본 걸 언급해도될듯)|
| (4) 기대효과 및 의의 |본 연구의 목표는 FAS 기술을 사용하고자 하는 모든 기술 및 기업을 목표 사용자로 하여, FLIP (Face Anti-Spoofing with Language-Image Pretraining) 모델의 추론 속도를 향상시켜 보다 효율적이고 실용적인 사용 환경을 조성하는 것이다. 구체적으로는 다음과 같은 목표를 설정하였다:<br><br> 1. FLIP 모델의 추론 속도를 기존보다 최소 2배 이상 향상시키는 것을 목표로 한다. 이를 통해 모델의 사용성을 향상시키고, 실제 환경에서의 빠른 응답이 가능하도록 한다.<br> 2. 작은 모델에게도 FLIP과 유사한 성능을 제공하여 모델의 크기를 줄이고 자원을 효율적으로 활용할 수 있도록 한다. 이를 통해 모바일 및 임베디드 시스템에서도 FLIP 기술을 적용할 수 있는 환경을 조성한다.<br> 3. 추론 속도의 향상이 모델의 정확도에 부정적인 영향을 미치지 않도록 한다. 즉, 속도와 정확도 간의 균형을 유지하여 실제 사용 시에도 뛰어난 성능을 제공한다.<br> 4. FLIP 모델의 개선을 통해 기업들은 보다 빠르고 정확한 FAS 인공지능 서비스를 제공할 수 있게 되어 산업 혁신과 경쟁력 강화에 기여할 것으로 기대된다.<br><br> 위 목표를 달성함으로써, FAS 태스크의 보안성을 높여 기술 사용자들의 불안함을 해소하고, FLIP 기반의 다중 모달 인공지능 모델을 보다 효율적으로 개발하고 실제 응용 환경에서의 적용 가능성을 높이고자 한다.|
| (5) 주요 기능 리스트 | 1. CLIP-KD : <br> 2. RKD : <br> 3. AFD : <br>|

<br>
 
# Project-Design
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | *프로젝트를 완성하기 위해 필요한 요구사항을 설명하기에 가장 적합한 방법을 선택하여 기술* <br> 예) <br> - 기능별 상세 요구사항(또는 유스케이스) <br> - 설계 모델(클래스 다이어그램, 클래스 및 모듈 명세서) <br> - UI 분석/설계 모델 <br> - E-R 다이어그램/DB 설계 모델(테이블 구조) |
| (2) 전체 시스템 구성 | *프로젝트를 위하여, SW 전체 시스템의 구조를 보인다. (가능하다면, 사용자도 포함) <br> 주요 SW 모듈을 보이고, 각각의 역할을 기술한다. <br>만약, 오픈소스 혹은 외부 모듈을 사용한다면 이또한 기술한다.* |
| (3) 진척도 및 검증내역 | *스타트 단계에서 검증한 내용에 대하여 간략히 기술하고, <br>그로쓰 단계의 전체 일정에 비추어, 진척도(%) 및 근거 내용을 기술한다.* |
| (4) 기타 | *기타 사항을 기술* |

<br>
